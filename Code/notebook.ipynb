{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d0b1d2-0582-4a02-b5ea-3249ea313b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6fbffd-b4ee-4b06-b5de-4d67dd0fd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text by removing punctations and words with length <= 2 and making text lower case\n",
    "\n",
    "def clean_text(text): \n",
    "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
    "    delete_dict[' '] = ' ' \n",
    "    table = str.maketrans(delete_dict)\n",
    "    text1 = text.translate(table)\n",
    "    textArr= text1.split()\n",
    "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
    "    return text2.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f4ff238-869b-479b-b810-391fc556eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts topic names to numbers to work with the model\n",
    "\n",
    "def topic_to_number(topic):\n",
    "    if topic == 'Sports':\n",
    "        return 0\n",
    "    elif topic == 'Economics':\n",
    "        return 1\n",
    "    elif topic == 'Medicine':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af39197e-9749-4c40-a2fa-130ebf0d3aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the complete dataset, pre-process text and split it to train and test (80%, 20%)\n",
    "\n",
    "train= pd.read_csv(\"../Complete Dataset/dataset.csv\")\n",
    "df_train = pd.DataFrame(train, columns=['Article', 'Topic'])\n",
    "df_train['Article'] = df_train['Article'].apply(clean_text)\n",
    "df_train.to_csv(\"../Complete Dataset/dataset_cleaned.csv\")\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    df_train,\n",
    "    test_size = 0.20,\n",
    "    random_state = 57,\n",
    "    stratify=df_train['Topic']\n",
    ")\n",
    "train_data.to_csv(\"../Training Data/train_data.csv\")\n",
    "test_data.to_csv(\"../Testing Data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2360636-1b48-4eef-9093-6af093bcf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test datasets\n",
    "\n",
    "train_data = pd.read_csv(\"../Training Data/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../Testing Data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08080cad-b885-422c-89d1-ce51982d818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medicine     80\n",
      "Sports       80\n",
      "Economics    80\n",
      "Name: Topic, dtype: int64\n",
      "Medicine     20\n",
      "Sports       20\n",
      "Economics    20\n",
      "Name: Topic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Topic'].value_counts())\n",
    "print(test_data['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471ee3a6-69bc-4a57-a73e-ac3913199890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Topic'] = train_data['Topic'].apply(topic_to_number)\n",
    "test_data['Topic'] = test_data['Topic'].apply(topic_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2032025d-5244-43e8-87b9-d163777afb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data to train and validation\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid= train_test_split(train_data['Article'].tolist(),\\\n",
    "                                                      train_data['Topic'].tolist(),\\\n",
    "                                                      test_size=0.2,\\\n",
    "                                                      stratify = train_data['Topic'].tolist(),\\\n",
    "                                                      random_state=57)\n",
    "train_dat =list(zip(Y_train,X_train))\n",
    "valid_dat =list(zip(Y_valid,X_valid))\n",
    "test_dat=list(zip(test_data['Topic'].tolist(),test_data['Article'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8dd85a-eefe-4165-ab0d-387672a48dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data len:192\n",
      "Topics distributionCounter({2: 64, 1: 64, 0: 64})\n",
      "Valid data len:48\n",
      "Topics distributionCounter({2: 16, 0: 16, 1: 16})\n",
      "Test data len:60\n",
      "Topics distributionCounter({2: 20, 0: 20, 1: 20})\n"
     ]
    }
   ],
   "source": [
    "print('Train data len:'+str(len(X_train)))\n",
    "print('Topics distribution'+str(Counter(Y_train)))\n",
    "\n",
    "\n",
    "print('Valid data len:'+str(len(X_valid)))\n",
    "print('Topics distribution'+ str(Counter(Y_valid)))\n",
    "\n",
    "print('Test data len:'+str(len(test_data['Article'].tolist())))\n",
    "print('Topics distribution'+ str(Counter(test_data['Topic'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35f87f4-5b15-4c1e-9170-f028145ed0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Work with the gpu (cuda)\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english') # torchtext tokenizer\n",
    "train_iter = train_dat\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "text_pipeline = lambda x: vocab(tokenizer(x)) # Build text pipleine using the vocab\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a263128-293e-4115-88a0-8a6061df3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function, needed for building pytorch dataloaders\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f5fd91-8f51-4328-ba13-46b1b7648cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "class TopicClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TopicClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True) # A text embedding layer\n",
    "        self.fc = nn.Linear(embed_dim, num_class) # A fully-connected layer\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65265ad7-9e90-497f-a7fc-2a29806ce678",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 3\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64 # Embedding size\n",
    "model = TopicClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09b1748-16c1-4899-94c8-5d8f62c685e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c777f4b-2230-4087-8109-7bc97430d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_dataloader = DataLoader(train_dat, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_dat, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dat, batch_size=BATCH_SIZE, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c228cf5-74fe-4b37-a5eb-ca361798b3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time:  9.28s | valid accuracy    0.333 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time:  0.45s | valid accuracy    0.417 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   3 | time:  0.46s | valid accuracy    0.583 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   4 | time:  0.46s | valid accuracy    0.833 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   5 | time:  0.44s | valid accuracy    0.896 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   6 | time:  0.45s | valid accuracy    0.938 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   7 | time:  0.43s | valid accuracy    0.938 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   8 | time:  0.46s | valid accuracy    0.938 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   9 | time:  0.41s | valid accuracy    0.958 \n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "| end of epoch  10 | time:  0.46s | valid accuracy    0.958 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 2.8 # learning rate\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.2)\n",
    "total_accu = None\n",
    "\n",
    "# Start Training\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid accuracy {:8.3f} '.format(epoch, time.time() - epoch_start_time, accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c325a6c-f967-4f71-8770-6b448dca9f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.933\n"
     ]
    }
   ],
   "source": [
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3cd784d-cf5c-4818-8015-6fa1ddc2384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_label = {0:\"Sports\", 1: \"Economics\", 2: \"Medicine\"}\n",
    "\n",
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = clean_text(text)\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e4549f6-5e50-4319-8c39-193e5b8ec178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Topic is: Sports\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"Man City win the 2021/22 Premier League title: Six games that helped Pep Guardiola’s side become champions\"\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"The Topic is: %s\" %topic_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ea74970-cb7e-460c-af81-c92b1025da4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Topic is: Economics\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"The recipe for the outperformance of Swiss businesses Common sense and low taxes make the Alpine nation a corporate haven\"\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"The Topic is: %s\" %topic_label[predict(ex_text_str, text_pipeline)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce64c0d9-a9ed-4093-a6b9-b4913ef4e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Topic is: Medicine\n"
     ]
    }
   ],
   "source": [
    "ex_text_str = \"COVID-19 Vaccine for Kids Under 5: Pfizer Says 3 Shots 80% Effective\"\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"The Topic is: %s\" %topic_label[predict(ex_text_str, text_pipeline)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
